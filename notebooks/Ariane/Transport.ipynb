{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arrow\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xarray as xr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Grid ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh = nc.Dataset('/home/sallen/MEOPAR/grid/mesh_mask201702.nc')\n",
    "#mesh = nc.Dataset('../../../myResults/mesh_mask201702.nc')\n",
    "gdepw = mesh.variables['gdepw_1d'][0]\n",
    "bathy = nc.Dataset('/home/sallen/MEOPAR/grid/bathymetry_201702.nc')\n",
    "#bathy = nc.Dataset('../../../myResults/bathymetry_201702.nc')\n",
    "lats = bathy.variables['nav_lat'][:]\n",
    "lons = bathy.variables['nav_lon'][:]\n",
    "mesh.close()\n",
    "bathy.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_transport(basedir, dir1, section):\n",
    "    filename = 'ariane_positions_quantitative.nc'\n",
    "    with nc.Dataset(os.path.join('/data/sallen/results/Ariane',basedir, dir1, filename)) as dataset:\n",
    "#    with nc.Dataset(os.path.join('../',basedir, dir1, filename)) as dataset:\n",
    "        final_section = dataset.variables['final_section'][:]\n",
    "        final_transport = dataset.variables['final_transp'][:]\n",
    "        vic_transport = np.sum(np.where(final_section == section, final_transport, 0))\n",
    "    return (vic_transport/24.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_all(basedir, dir1, section, allv):\n",
    "    final = {}\n",
    "    mean = {}    \n",
    "    filename = 'ariane_positions_quantitative.nc'\n",
    "    with nc.Dataset(os.path.join('/data/sallen/results/Ariane',basedir, dir1, filename)) as dataset:\n",
    "#    with nc.Dataset(os.path.join('../',basedir, dir1, filename)) as dataset:\n",
    "        final_section = dataset.variables['final_section'][:]\n",
    "        final_transport = dataset.variables['final_transp'][:]\n",
    "        vic_transport = np.sum(np.where(final_section == section, final_transport, 0))\n",
    "        for variable in allv:\n",
    "            if variable == 'final_age':\n",
    "                scale = 86400. # convert from seconds to days\n",
    "            else:\n",
    "                scale = 1.\n",
    "            final[variable] = dataset.variables[variable][:]/scale\n",
    "            mean[variable] = np.sum(np.where(final_section == section, final_transport*final[variable], 0))/vic_transport\n",
    "    return vic_transport/24., mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(start, endtime, basedir, section):\n",
    "    transport = np.zeros(365*2+1)\n",
    "    timerange = arrow.Arrow.range('day', start, endtime)\n",
    "    time = []\n",
    "    for i, r in enumerate(timerange):\n",
    "        dir1 = r.format('DDMMMYY').lower()\n",
    "        transport[i] = calculate_transport(basedir, dir1, section)\n",
    "#        transport[i] = calculate_transport('./', './', section)\n",
    "        time.append(r.datetime)\n",
    "    return time, transport[:len(timerange)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_all(start, endtime, basedir, section, allv):\n",
    "    timerange = arrow.Arrow.range('day', start, endtime)\n",
    "    length = len(timerange)\n",
    "    transport = np.zeros(length)\n",
    "    mean = {}\n",
    "    for variable in allv:\n",
    "        mean[variable] = np.zeros(length)\n",
    "    time = []\n",
    "    for i, r in enumerate(timerange):\n",
    "        dir1 = r.format('DDMMMYY').lower()\n",
    "#        print (dir1)\n",
    "        transport[i], meanday = calculate_all(basedir, dir1, section, allv)\n",
    "        for variable in allv:\n",
    "            mean[variable][i] = meanday[variable]\n",
    "        time.append(r.datetime)\n",
    "    return time, transport, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_position(basedir, dir1, section, fi, ff):\n",
    "    print(fi, ff)\n",
    "    filename = 'ariane_positions_quantitative.nc'\n",
    "    with nc.Dataset(os.path.join('/data/sallen/results/Ariane',basedir, dir1, filename)) as dataset:\n",
    "#    with nc.Dataset(os.path.join('../',basedir, dir1, filename)) as dataset:\n",
    "        final_section = dataset.variables['final_section'][:]\n",
    "        final_transport = dataset.variables['final_transp'][:]\n",
    "        final_depth = dataset.variables['final_depth'][:]\n",
    "        final_lon = dataset.variables['final_lon'][:]\n",
    "        final_lat = dataset.variables['final_lat'][:]\n",
    "        init_depth = dataset.variables['init_depth'][:]\n",
    "        init_lat = dataset.variables['init_lat'][:]\n",
    "        init_lon = dataset.variables['init_lon'][:]\n",
    "        for part in range(final_section.shape[0]):\n",
    "            if final_section[part] == section:\n",
    "                fi.write('{0:4f} {1:4f} {2:4f} {3:4f} \\n'.format(\n",
    "                    init_depth[part], init_lat[part], init_lon[part], final_transport[part]))\n",
    "                ff.write('{0:4f} {1:4f} {2:4f} {3:4f} \\n'.format(\n",
    "                    final_depth[part], final_lat[part], final_lon[part], final_transport[part]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01jan15\n",
      "02jan15\n",
      "03jan15\n",
      "04jan15\n",
      "05jan15\n",
      "06jan15\n",
      "07jan15\n",
      "08jan15\n",
      "09jan15\n",
      "10jan15\n",
      "11jan15\n",
      "12jan15\n",
      "13jan15\n",
      "14jan15\n",
      "15jan15\n",
      "16jan15\n",
      "17jan15\n",
      "18jan15\n",
      "19jan15\n",
      "20jan15\n",
      "21jan15\n",
      "22jan15\n",
      "23jan15\n",
      "24jan15\n",
      "25jan15\n",
      "26jan15\n",
      "27jan15\n",
      "28jan15\n",
      "29jan15\n",
      "30jan15\n",
      "31jan15\n",
      "01feb15\n",
      "02feb15\n",
      "03feb15\n",
      "04feb15\n",
      "05feb15\n",
      "06feb15\n",
      "07feb15\n",
      "08feb15\n",
      "09feb15\n",
      "10feb15\n",
      "11feb15\n",
      "12feb15\n",
      "13feb15\n",
      "14feb15\n",
      "15feb15\n",
      "16feb15\n",
      "17feb15\n",
      "18feb15\n",
      "19feb15\n",
      "20feb15\n",
      "21feb15\n",
      "22feb15\n",
      "23feb15\n",
      "24feb15\n",
      "25feb15\n",
      "26feb15\n",
      "27feb15\n",
      "28feb15\n",
      "01mar15\n",
      "02mar15\n",
      "03mar15\n",
      "04mar15\n",
      "05mar15\n",
      "06mar15\n",
      "07mar15\n",
      "08mar15\n",
      "09mar15\n",
      "10mar15\n",
      "11mar15\n",
      "12mar15\n",
      "13mar15\n",
      "14mar15\n",
      "15mar15\n",
      "16mar15\n",
      "17mar15\n",
      "18mar15\n",
      "19mar15\n",
      "20mar15\n",
      "21mar15\n",
      "22mar15\n",
      "23mar15\n",
      "24mar15\n",
      "25mar15\n",
      "26mar15\n",
      "27mar15\n",
      "28mar15\n",
      "29mar15\n",
      "30mar15\n",
      "31mar15\n",
      "01apr15\n",
      "02apr15\n",
      "03apr15\n",
      "04apr15\n",
      "05apr15\n",
      "06apr15\n",
      "07apr15\n",
      "08apr15\n",
      "09apr15\n",
      "10apr15\n",
      "11apr15\n",
      "12apr15\n",
      "13apr15\n",
      "14apr15\n",
      "15apr15\n",
      "16apr15\n",
      "17apr15\n",
      "18apr15\n",
      "19apr15\n",
      "20apr15\n",
      "21apr15\n",
      "22apr15\n",
      "23apr15\n",
      "24apr15\n",
      "25apr15\n",
      "26apr15\n",
      "27apr15\n",
      "28apr15\n",
      "29apr15\n",
      "30apr15\n",
      "01may15\n",
      "02may15\n",
      "03may15\n",
      "04may15\n",
      "05may15\n",
      "06may15\n",
      "07may15\n",
      "08may15\n",
      "09may15\n",
      "10may15\n",
      "11may15\n",
      "12may15\n",
      "13may15\n",
      "14may15\n",
      "15may15\n",
      "16may15\n",
      "17may15\n",
      "18may15\n",
      "19may15\n",
      "20may15\n",
      "21may15\n",
      "22may15\n",
      "23may15\n",
      "24may15\n",
      "25may15\n",
      "26may15\n",
      "27may15\n",
      "28may15\n",
      "29may15\n",
      "30may15\n",
      "31may15\n",
      "01jun15\n",
      "02jun15\n",
      "03jun15\n",
      "04jun15\n",
      "05jun15\n",
      "06jun15\n",
      "07jun15\n",
      "08jun15\n",
      "09jun15\n",
      "10jun15\n",
      "11jun15\n",
      "12jun15\n",
      "13jun15\n",
      "14jun15\n",
      "15jun15\n",
      "16jun15\n",
      "17jun15\n",
      "18jun15\n",
      "19jun15\n",
      "20jun15\n",
      "21jun15\n",
      "22jun15\n",
      "23jun15\n",
      "24jun15\n",
      "25jun15\n",
      "26jun15\n",
      "27jun15\n",
      "28jun15\n",
      "29jun15\n",
      "30jun15\n",
      "01jul15\n",
      "02jul15\n",
      "03jul15\n",
      "04jul15\n",
      "05jul15\n",
      "06jul15\n",
      "07jul15\n",
      "08jul15\n",
      "09jul15\n",
      "10jul15\n",
      "11jul15\n",
      "12jul15\n",
      "13jul15\n",
      "14jul15\n",
      "15jul15\n",
      "16jul15\n",
      "17jul15\n",
      "18jul15\n",
      "19jul15\n",
      "20jul15\n",
      "21jul15\n",
      "22jul15\n",
      "23jul15\n",
      "24jul15\n",
      "25jul15\n",
      "26jul15\n",
      "27jul15\n",
      "28jul15\n",
      "29jul15\n",
      "30jul15\n",
      "31jul15\n",
      "01aug15\n",
      "02aug15\n",
      "03aug15\n",
      "04aug15\n",
      "05aug15\n",
      "06aug15\n",
      "07aug15\n",
      "08aug15\n",
      "09aug15\n",
      "10aug15\n",
      "11aug15\n",
      "12aug15\n",
      "13aug15\n",
      "14aug15\n",
      "15aug15\n",
      "16aug15\n",
      "17aug15\n",
      "18aug15\n",
      "19aug15\n",
      "20aug15\n",
      "21aug15\n",
      "22aug15\n",
      "23aug15\n",
      "24aug15\n",
      "25aug15\n",
      "26aug15\n",
      "27aug15\n",
      "28aug15\n",
      "29aug15\n",
      "30aug15\n",
      "31aug15\n",
      "01sep15\n",
      "02sep15\n",
      "03sep15\n",
      "04sep15\n",
      "05sep15\n",
      "06sep15\n",
      "07sep15\n",
      "08sep15\n",
      "09sep15\n",
      "10sep15\n",
      "11sep15\n",
      "12sep15\n",
      "13sep15\n",
      "14sep15\n",
      "15sep15\n",
      "16sep15\n",
      "17sep15\n",
      "18sep15\n",
      "19sep15\n",
      "20sep15\n",
      "21sep15\n",
      "22sep15\n",
      "23sep15\n",
      "24sep15\n",
      "25sep15\n",
      "26sep15\n",
      "27sep15\n",
      "28sep15\n",
      "29sep15\n",
      "30sep15\n",
      "01oct15\n",
      "02oct15\n",
      "03oct15\n",
      "04oct15\n",
      "05oct15\n",
      "06oct15\n",
      "07oct15\n",
      "08oct15\n",
      "09oct15\n",
      "10oct15\n",
      "11oct15\n",
      "12oct15\n",
      "13oct15\n",
      "14oct15\n",
      "15oct15\n",
      "16oct15\n",
      "17oct15\n",
      "18oct15\n",
      "19oct15\n",
      "20oct15\n",
      "21oct15\n",
      "22oct15\n",
      "23oct15\n",
      "24oct15\n",
      "25oct15\n",
      "26oct15\n",
      "27oct15\n",
      "28oct15\n",
      "29oct15\n",
      "30oct15\n",
      "31oct15\n",
      "01nov15\n",
      "02nov15\n",
      "03nov15\n",
      "04nov15\n",
      "05nov15\n",
      "06nov15\n",
      "07nov15\n",
      "08nov15\n",
      "09nov15\n",
      "10nov15\n",
      "11nov15\n",
      "12nov15\n",
      "13nov15\n",
      "14nov15\n",
      "15nov15\n",
      "16nov15\n",
      "17nov15\n",
      "18nov15\n",
      "19nov15\n",
      "20nov15\n",
      "21nov15\n",
      "22nov15\n",
      "23nov15\n",
      "24nov15\n",
      "25nov15\n",
      "26nov15\n",
      "27nov15\n",
      "28nov15\n",
      "29nov15\n",
      "30nov15\n",
      "01dec15\n",
      "02dec15\n",
      "03dec15\n",
      "04dec15\n",
      "05dec15\n",
      "06dec15\n",
      "07dec15\n",
      "08dec15\n",
      "09dec15\n",
      "10dec15\n",
      "11dec15\n",
      "12dec15\n",
      "13dec15\n",
      "14dec15\n",
      "15dec15\n",
      "16dec15\n",
      "17dec15\n",
      "18dec15\n",
      "19dec15\n",
      "20dec15\n",
      "21dec15\n",
      "22dec15\n",
      "23dec15\n",
      "24dec15\n",
      "25dec15\n",
      "26dec15\n",
      "27dec15\n",
      "28dec15\n",
      "29dec15\n",
      "30dec15\n",
      "31dec15\n"
     ]
    }
   ],
   "source": [
    "# Full South Vic -> PR (2)\n",
    "allv = ['final_age', 'final_depth', 'final_salt', 'final_temp', 'final_lon', \n",
    "        'init_depth', 'init_salt', 'init_temp', 'init_lat']\n",
    "start = datetime.datetime(2015, 1, 1)\n",
    "endtime = datetime.datetime(2015, 12, 31)\n",
    "time, transport, mean = get_data_all(start, endtime, 'FullSouth', 2, allv)\n",
    "fullsouth_all = pd.DataFrame(data=transport, index=time, columns=['transport'])\n",
    "for variable in allv:\n",
    "    fullsouth_all = fullsouth_all.assign(mycol=pd.Series(mean[variable]).values)\n",
    "    fullsouth_all.rename(columns={'mycol':variable}, inplace=True)\n",
    "fullsouth_all\n",
    "fullsouth_all.to_csv('Vic_to_PR_2015_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Full South Vic -> GI (3)\n",
    "allv = ['final_age', 'final_depth', 'final_salt', 'final_temp', 'final_lon', \n",
    "        'init_depth', 'init_salt', 'init_temp', 'init_lat']\n",
    "start = datetime.datetime(2015, 1, 1)\n",
    "endtime = datetime.datetime(2015, 12, 31)\n",
    "time, transport, mean = get_data_all(start, endtime, 'FullSouth', 3, allv)\n",
    "fullsouth_all = pd.DataFrame(data=transport, index=time, columns=['transport'])\n",
    "for variable in allv:\n",
    "    fullsouth_all = fullsouth_all.assign(mycol=pd.Series(mean[variable]).values)\n",
    "    fullsouth_all.rename(columns={'mycol':variable}, inplace=True)\n",
    "fullsouth_all\n",
    "fullsouth_all.to_csv('Vic_to_GI_2015_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Back North into PR from Vic\n",
    "allv = ['final_age', 'final_depth', 'final_salt', 'final_temp', 'final_lon', \n",
    "        'init_depth', 'init_salt', 'init_temp', 'init_lat']\n",
    "start = datetime.datetime(2015, 1, 1)\n",
    "endtime = datetime.datetime(2015, 12, 31)\n",
    "time, transport, mean = get_data_all(start, endtime, 'BackNorth', 2, allv)\n",
    "fullsouth_all = pd.DataFrame(data=transport, index=time, columns=['transport'])\n",
    "for variable in allv:\n",
    "    fullsouth_all = fullsouth_all.assign(mycol=pd.Series(mean[variable]).values)\n",
    "    fullsouth_all.rename(columns={'mycol':variable}, inplace=True)\n",
    "fullsouth_all\n",
    "fullsouth_all.to_csv('PR_from_Vic_2015_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In GIslands into GI from Vic\n",
    "allv = ['final_age', 'final_depth', 'final_salt', 'final_temp', 'final_lon', \n",
    "        'init_depth', 'init_salt', 'init_temp', 'init_lat']\n",
    "start = datetime.datetime(2015, 1, 1)\n",
    "endtime = datetime.datetime(2015, 12, 31)\n",
    "time, transport, mean = get_data_all(start, endtime, 'InGIslands', 2, allv)\n",
    "fullsouth_all = pd.DataFrame(data=transport, index=time, columns=['transport'])\n",
    "for variable in allv:\n",
    "    fullsouth_all = fullsouth_all.assign(mycol=pd.Series(mean[variable]).values)\n",
    "    fullsouth_all.rename(columns={'mycol':variable}, inplace=True)\n",
    "fullsouth_all\n",
    "fullsouth_all.to_csv('GI_from_Vic_2015_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Full North PR to Vic\n",
    "allv = ['final_age', 'final_depth', 'final_salt', 'final_temp', 'final_lon', \n",
    "        'init_depth', 'init_salt', 'init_temp', 'init_lat']\n",
    "start = datetime.datetime(2015, 1, 1)\n",
    "endtime = datetime.datetime(2015, 12, 31)\n",
    "time, transport, mean = get_data_all(start, endtime, 'FullNorth', 2, allv)\n",
    "fullnorth_all = pd.DataFrame(data=transport, index=time, columns=['transport'])\n",
    "for variable in allv:\n",
    "    fullnorth_all = fullnorth_all.assign(mycol=pd.Series(mean[variable]).values)\n",
    "    fullnorth_all.rename(columns={'mycol':variable}, inplace=True)\n",
    "fullnorth_all\n",
    "fullnorth_all.to_csv('PR_to_Vic_2015_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# South G Islands GI to Vic\n",
    "allv = ['final_age', 'final_depth', 'final_salt', 'final_temp', 'final_lon', \n",
    "        'init_depth', 'init_salt', 'init_temp', 'init_lat']\n",
    "start = datetime.datetime(2015, 1, 1)\n",
    "endtime = datetime.datetime(2015, 12, 31)\n",
    "time, transport, mean = get_data_all(start, endtime, 'SouthGIslands', 2, allv)\n",
    "fullsouth_all = pd.DataFrame(data=transport, index=time, columns=['transport'])\n",
    "for variable in allv:\n",
    "    fullsouth_all = fullsouth_all.assign(mycol=pd.Series(mean[variable]).values)\n",
    "    fullsouth_all.rename(columns={'mycol':variable}, inplace=True)\n",
    "fullsouth_all\n",
    "fullsouth_all.to_csv('GI_to_Vic_2015_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BackSouth Vic from PR\n",
    "allv = ['final_age', 'final_depth', 'final_salt', 'final_temp', 'final_lon', \n",
    "        'init_depth', 'init_salt', 'init_temp', 'init_lat']\n",
    "start = datetime.datetime(2015, 1, 1)\n",
    "endtime = datetime.datetime(2015, 12, 31)\n",
    "time, transport, mean = get_data_all(start, endtime, 'BackSouth', 2, allv)\n",
    "fullsouth_all = pd.DataFrame(data=transport, index=time, columns=['transport'])\n",
    "for variable in allv:\n",
    "    fullsouth_all = fullsouth_all.assign(mycol=pd.Series(mean[variable]).values)\n",
    "    fullsouth_all.rename(columns={'mycol':variable}, inplace=True)\n",
    "fullsouth_all\n",
    "fullsouth_all.to_csv('Vic_from_PR_2015_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BackSouth Vic from GI\n",
    "allv = ['final_age', 'final_depth', 'final_salt', 'final_temp', 'final_lon', \n",
    "        'init_depth', 'init_salt', 'init_temp', 'init_lat']\n",
    "start = datetime.datetime(2015, 1, 1)\n",
    "endtime = datetime.datetime(2015, 12, 31)\n",
    "time, transport, mean = get_data_all(start, endtime, 'BackSouth', 3, allv)\n",
    "fullnorth_all = pd.DataFrame(data=transport, index=time, columns=['transport'])\n",
    "for variable in allv:\n",
    "    fullnorth_all = fullnorth_all.assign(mycol=pd.Series(mean[variable]).values)\n",
    "    fullnorth_all.rename(columns={'mycol':variable}, inplace=True)\n",
    "fullnorth_all\n",
    "fullnorth_all.to_csv('Vic_from_GI_2015_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi = open('south_init.txt', 'a')\n",
    "ff = open('south_final.txt', 'a')\n",
    "save_position('./', './', 2, fi, ff)\n",
    "fi.close() \n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Victoria_sill_j = 178-1;\n",
    "#    Victoria_sill_i = np.arange(235,302+1)-1\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "with open('south_init.txt', 'r') as fi:\n",
    "    mydata = np.loadtxt(fi)\n",
    "my_lats_edges = lats[235-1:302-1, 178-1] - (lats[235, 178] - lats[234, 178])/2.\n",
    "my_deps_edges = -gdepw[28::-1]\n",
    "H, xs, ys = np.histogram2d(mydata[:, 0], mydata[:, 1],  bins = [my_deps_edges, my_lats_edges],\n",
    "                        weights=mydata2[:,3])\n",
    "mesh = ax[0].pcolormesh(my_lats_edges[:-1], my_deps_edges[:-1], H)\n",
    "fig.colorbar(mesh, ax=ax[0])\n",
    "\n",
    "with open('south_final.txt', 'r') as ff:\n",
    "    mydata2 = np.loadtxt(ff)\n",
    "my_lons_edges = lons[387-1, 262-1:309-1] - (lons[387, 300] - lons[387, 301])/2.\n",
    "H, xs, ys = np.histogram2d(mydata2[:, 0], mydata2[:, 2],  bins = [my_deps_edges, my_lons_edges],\n",
    "                        weights=mydata2[:,3])\n",
    "mesh = ax[1].pcolormesh(my_lons_edges[:-1], my_deps_edges[:-1], H)\n",
    "fig.colorbar(mesh, ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(18, 6))\n",
    "ax2 = ax.twinx()\n",
    "fullsouth_transport.plot(ax=ax, y='transport', label=\"South to North\", legend=False)\n",
    "fullnorth_transport.plot(ax=ax, y='transport', label=\"North to South (shallow)\", legend=False)\n",
    "fullsouth_transport_16.plot(ax=ax, y='transport', label=\"South to North (deep)\", legend=False, c='b')\n",
    "fullnorth_transport_16.plot(ax=ax, y='transport', label=\"North to South (shallow)\", legend=False, c='g')\n",
    "#low_pass_tide.plot(ax=ax2, c='r')\n",
    "ax.set_xlim(fullsouth_transport.index[0], time[-1])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Tides moved to \"Calculate Tides\" ##\n",
    "Here just read them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_pass_tide = pd.read_csv('low_pass_tide.csv')\n",
    "low_pass_tide.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "ax2 = ax.twinx()\n",
    "lag = 0\n",
    "ii, jj = 0-min(0,lag), 290-min(0,lag)\n",
    "ax.plot(range(ii, jj), fullnorth_transport['transport'][ii+lag:jj+lag])\n",
    "ax2.plot(range(ii, jj), -low_pass_tide['uVelocity'][ii:jj], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "ax2 = ax.twinx()\n",
    "lag = 0\n",
    "ii, jj = 150-min(0,lag), 290-min(0,lag)\n",
    "ax.plot(range(ii, jj), fullnorth_transport['transport'][ii+lag:jj+lag], 'o-')\n",
    "ax2.plot(range(ii, jj), low_pass_tide['uVelocity'][ii:jj], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summer Deep Water Variability ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "ax2 = ax.twinx()\n",
    "lag = -3\n",
    "ii, jj = 190, 300\n",
    "ax.plot(range(ii, jj),fullsouth_transport['transport'][ii+lag:jj+lag])\n",
    "ax2.plot(range(ii, jj), -low_pass_tide['uVelocity'][ii:jj], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spring Deep Water Variability ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "ax2 = ax.twinx()\n",
    "lag = -3\n",
    "ii, jj = 100, 190\n",
    "ax.plot(range(ii, jj),fullsouth_transport['transport'][ii+lag:jj+lag])\n",
    "ax2.plot(range(ii, jj), -low_pass_tide['uVelocity'][ii:jj], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winter Deep Water Variability : note change in lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "ax2 = ax.twinx()\n",
    "lag = -5\n",
    "ii, jj = 0-lag, 100\n",
    "ax.plot(range(ii, jj),fullsouth_transport['transport'][ii+lag:jj+lag])\n",
    "ax2.plot(range(ii, jj), -low_pass_tide['uVelocity'][ii:jj], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh = nc.Dataset('/home/sallen/MEOPAR/grid/mesh_mask201702.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracers = nc.Dataset('https://salishsea.eos.ubc.ca/erddap/griddap/ubcSSg3DTracerFields1hV17-02')\n",
    "iY = 258; iX = 178; iZ = 28\n",
    "iY2 = 388; iX2 = 271\n",
    "salinity = tracers.variables['salinity'][0:24*365:24, :iZ, iY, iX]\n",
    "salinity2 = tracers.variables['salinity'][0:24*365:24, :iZ, iY2, iX2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e3t = mesh.variables['e3t_0'][0, :iZ, iY, iX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saldiff = np.zeros(365)\n",
    "for i in range(365):\n",
    "    saldiff[i] = np.sum(salinity[i]*e3t) - np.sum(salinity2[i]*e3t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 5))\n",
    "ax2 = ax.twinx()\n",
    "ax.plot(saldiff)\n",
    "ax2.plot(range(0, 290), fullsouth_transport['transport'][0:290], 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = open('gulfisland_fullsouth_early2015', 'wb')\n",
    "pickle.dump(gulfislands, fs)\n",
    "fs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = open('fullsouth_early2015', 'wb')\n",
    "pickle.dump(fullsouth_transport, fs)\n",
    "fs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vic_transport_2015 = pickle.load('vic_transport_2015')\n",
    "plt.plot(vic_transport_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = open('vic_transport_2015', 'wb')\n",
    "pickle.dump(vic_transport, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vsq = pd.read_csv('../day_avg_tide_pd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(18, 5))\n",
    "for i, lag in enumerate(range(-7, 7, 3)):\n",
    "    ax[i].plot(vsq[99+lag:99+365+lag].uVelocity, vic_transport, '*')\n",
    "#    print (np.correlate(vsq[99+lag:99+365+lag], vic_transport[:]), lag, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (final_section[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (final_transport[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
